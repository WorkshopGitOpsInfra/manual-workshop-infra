= Managed cluster setup

Then checkout and create a new branch for your user. 

[.lines_7]
[.console-input]
[source, shell,subs="+macros,+attributes"]
----
git branch # main
git checkout -b sno-<name>-setup
----

Argo hub setup has been already performed, so you just need to focused on managed your single node cluster.

As every user is deploying its own bootstrap file, they must have an unique name and they should be deployed on your scoped project where your user has privileges.

Then you will have to replace <name> by your cluster and your repo url to your github account.

Make sure after cluster-definition, the following folder (sno-<name>) is named as your assigned cluster as this value will be used as a parameter for ApplicationSet.
Then update cluster.json values.

[.lines_7]
[.console-input]
[source, shell,subs="+macros,+attributes"]
----
{
  "environment": "dev",
  "cloud": "aws",
  "project": "project-sno-<name>",
  "region": "<region>",
  "cluster": {
    "name": "sno-<name>",
    "address": "https://api.sno-<name>.<domain>.opentlc.com:6443"
  }
}
----

You must also update managed-setup-a for your own managed cluster. Note how this application deploys to a different namespace and argo instance compared to hub-setup application:

[.lines_7]
[.console-input]
[source, shell,subs="+macros,+attributes"]
----
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: managed-setup-a-<name>
  namespace: openshift-operators
spec:
  destination:
    namespace: openshift-operators
    server: https://kubernetes.default.svc
  project: project-sno-<name>
  source:
    repoURL: https://github.com/<your_user>/workshop-gitops-content-deploy.git
    targetRevision: sno-<name>-setup
    path: cluster-addons/cluster-addons-as/
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
----      

The source path of this Application points to the https://argo-cd.readthedocs.io/en/stable/user-guide/application-set/[ApplicationSet] used. 
ApplicationSet is a CR that can be uset to genereate Applications to multiple cluster from multiple originis. ApplicationSet controller is installed alongside Argo CD 
even though it must be explicitaly enabled. 

ApplicationSet is a helpful approach for multi cluster management, and it "supplements Argo CD by adding additional features in support of cluster-administrator-focused scanerios". Some of those are:

- Ability to use a single Kubernetes manifest to target multiple Kubernetes clusters with Argo CD.

- Ability to use a single Kubernetes manifest to deploy multiple applications from one or multiple Git repositories with Argo CD.

- Improved support for monorepos (multiple Argo CD Application resources defined within a single Git repository).

- Improves ability of individual cluster tenants to deploy applications using ArgoCD (without needing to involve privileged cluster admin in enabling the destanion servers).

ApplicationSet uses generators to create Application with multiple origins and destinations using templating. 

https://argo-cd.readthedocs.io/en/stable/operator-manual/applicationset/Generators/[Generator] used may vary depending on your use case, in this example
we are using Git Files generator so cluster definition values are used as parameters. In case we had N cluster-definition files, the ApplicationSet would generate N Applications automatically.

As we did before, we should update ApplicationSet name with your lab data.

[.lines_7]
[.console-input]
[source, shell,subs="+macros,+attributes"]
----
apiVersion: argoproj.io/v1alpha1
kind: ApplicationSet
metadata:
  name: gitops-setup-sno-<name>
  namespace: openshift-operators
spec:
  generators:
  - git:
      repoURL: https://github.com/romerobu/workshop-gitops-content-deploy.git
      revision: sno-<name>-setup
      files:
      - path: "cluster-definition/**/cluster.json"
  template:
    metadata:
      name: 'gitops-setup-{{cluster.name}}-a'
    spec:
      project: '{{project}}'
      source:
        repoURL: https://github.com/<your_user>/workshop-gitops-content-deploy.git
        targetRevision: sno-<name>-setup
        path: cluster-addons/charts/gitops-setup 
      destination:
        server: '{{cluster.address}}'
      syncPolicy:
        automated:
          prune: true
          selfHeal: true       
----    

This first ApplicationSet deploys the operator and an initial non default cluster wide instance for day 2 and infra operations.

[.lines_7]
[.console-input]
[source, shell,subs="+macros,+attributes"]
----
apiVersion: argoproj.io/v1alpha1
kind: ApplicationSet
metadata:
  name: bootstrap-sno-<name>
  namespace: openshift-operators
spec:
  generators:
  - git:
      repoURL: https://github.com/romerobu/workshop-gitops-content-deploy.git
      revision: sno-<name>-setup
      files:
      - path: "cluster-definition/**/cluster.json"
  template:
    metadata:
      name: 'bootstrap-{{cluster.name}}-a'
    spec:
      project: '{{project}}'
      source:
        repoURL: https://github.com/<your_user>/workshop-gitops-content-deploy.git
        targetRevision: sno-<name>-setup
        path: cluster-addons/charts/bootstrap-app
      destination:
        server: '{{cluster.address}}'
      syncPolicy:
        automated:
          prune: true
          selfHeal: true       
----     

Then update bootstrap-app values.yaml file with your cluster data too:

[.lines_7]
[.console-input]
[source, shell,subs="+macros,+attributes"]
----
clusters:
  sno-<name>:
    applicationNamespace: openshift-gitops
    namespace: ''
    destination: 'https://kubernetes.default.svc'
    project: default
    code:
      repo: https://github.com/<your_user>/workshop-gitops-content-deploy.git
      path: cluster-addons/charts/bootstrap
      target: sno-<name>-setup
----

This ApplicationSet deploys an Application on the recently deployed instance on destination cluster to deploy and manage a second instance for applications.

Then navigate under source path to take a look to the Helm charts used for deploying GitOps and setting up the initial config for managed clusters.

*Reminder*: ApplicationSet controller is not enabled by default and must be configured on argocd instance.